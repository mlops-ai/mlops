{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca79d2e5",
   "metadata": {},
   "source": [
    "# mlops-ai library showcase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2756637",
   "metadata": {},
   "source": [
    "**Hello user!** ðŸ‘‹\n",
    "\n",
    "This is an end-to-end notebook to showcase key features of [mlops-ai](https://pypi.org/project/mlops-ai/) library, detailed library documentation can be also found [here](https://mlops-ai.github.io/mlops/library_docs/library_overview.html). <br> [MLOps](https://github.com/mlops-ai/mlops) is an open-source project to help Machine Learning professionals during managing model creation process (**tracking** module), but also monitoring a deployed model working on real-world data (**monitoring** module) with an optional email alerting system (**email alerts** module). More information can be found inside [README](https://github.com/mlops-ai/mlops?tab=readme-ov-file#mlops)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1991c38",
   "metadata": {},
   "source": [
    "## Library and application installation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6653fd",
   "metadata": {},
   "source": [
    "So as to install the library run, the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af5c39a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:48.833680Z",
     "start_time": "2024-01-04T13:03:48.825163Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install mlops-ai tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68677b74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:55.205208Z",
     "start_time": "2024-01-04T13:03:51.650716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mlops-ai\n",
      "Version: 1.2.8\n",
      "Summary: Mlops-ai library for managing machine learning projects, experiments, iterations and datasets.\n",
      "Home-page: \n",
      "Author: Kacper PÄ™kalski, Kajetan Szal, JÄ™drzej RybczyÅ„ski\n",
      "Author-email: kac.pekalski1@gmail.com\n",
      "License: Apache License 2.0\n",
      "Location: c:\\users\\jedryb\\anaconda3\\lib\\site-packages\n",
      "Requires: json2html, requests, scikit-learn, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show mlops-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c0149",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T18:41:01.369311Z",
     "start_time": "2024-01-02T18:41:01.362312Z"
    }
   },
   "source": [
    "To install the application follow the steps in [README](https://github.com/mlops-ai/mlops?tab=readme-ov-file#installation--usage). Essentially, you need to have [docker](https://docs.docker.com/get-docker/) and \n",
    "[docker-compose](https://docs.docker.com/compose/install/) installed on your machine. \n",
    "Then, you can clone the repository and run following command:\n",
    "\n",
    "```bash\n",
    "docker-compose up\n",
    "```\n",
    "\n",
    "After that you can access the application at [http://localhost:3000](http://localhost:3000)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1e1c9",
   "metadata": {},
   "source": [
    "## Tracking module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67845a03",
   "metadata": {},
   "source": [
    "### Creating a project\n",
    "\n",
    "MLOps project is a single machine learning project placeholder that consists of multiple experiments and models run as iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8837e48b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:55.298657Z",
     "start_time": "2024-01-04T13:03:55.206209Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlops.tracking import create_project, get_project, set_active_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0383482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:55.314688Z",
     "start_time": "2024-01-04T13:03:55.299689Z"
    }
   },
   "outputs": [],
   "source": [
    "project = create_project(\n",
    "    title=\"Iris classification\", \n",
    "    description=\"This project is focused on three Iris species multi-classification\",\n",
    "    status='in_progress'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e58e117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:55.345213Z",
     "start_time": "2024-01-04T13:03:55.317693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Active project set to: 6596acbb7826134dfca22750'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_active_project(project_id=project['_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3601b",
   "metadata": {},
   "source": [
    "### Creating a first experiment\n",
    "\n",
    "MLOps experiment is a machine learning experiment that can contain many iterations. Let's create an example experiment about KNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de895e7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:55.361217Z",
     "start_time": "2024-01-04T13:03:55.346214Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlops.tracking import create_experiment, get_experiment, set_active_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2da3b238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:55.393327Z",
     "start_time": "2024-01-04T13:03:55.365218Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = create_experiment(\n",
    "    # project_id=project['_id'] don't have to pass, since we have set active project\n",
    "    name=\"KNN models\",\n",
    "    description=\"Experimenting with different KNN models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b7f03de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:55.827698Z",
     "start_time": "2024-01-04T13:03:55.811695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Active experiment set to: 6596acbb7826134dfca22751'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_active_experiment(experiment_id=experiment['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda257ae",
   "metadata": {},
   "source": [
    "### Creating multiple iterations for our experiment\n",
    "\n",
    "Creating some example iterations of [KNN scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) machine learning models trained on Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc1f31a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:57.085784Z",
     "start_time": "2024-01-04T13:03:56.134966Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/TripathiAshutosh/dataset/main/iris.csv'\n",
    "df = pd.read_csv(filepath_or_buffer=url, sep=',')\n",
    "y = LabelEncoder().fit_transform(df['class'])\n",
    "X = df.drop(columns=['class'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify = y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd39834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:57.101100Z",
     "start_time": "2024-01-04T13:03:57.087582Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlops.tracking import start_iteration\n",
    "\n",
    "\n",
    "def log_single_iteration(iteration_name: str, model_name: str,\n",
    "                         model_params: dict = None,\n",
    "                         metrics: dict = None,\n",
    "                         model_path: str = None,\n",
    "                         dataset_id: str = None,\n",
    "                         interactive_charts: list = None):\n",
    "    \"\"\"\n",
    "    Util function for creating single mlops iteration.\n",
    "    \n",
    "    Args:\n",
    "        iteration_name (str): name of the whole iteration\n",
    "        model_name (str): name of the logged model\n",
    "        model_params (dict): parameters of model\n",
    "        metrics (dict): model metrics\n",
    "        model_path (str): path to saved model file\n",
    "        dataset_id (str): id to dataset from datasets tab\n",
    "    \"\"\"\n",
    "    with start_iteration(iteration_name=iteration_name) as iteration:\n",
    "        if model_params:\n",
    "            iteration.log_parameters(parameters=model_params)\n",
    "            \n",
    "        if metrics:\n",
    "            iteration.log_metrics(metrics=metrics)\n",
    "            \n",
    "        if model_path:\n",
    "            iteration.log_path_to_model(path_to_model=model_path)\n",
    "        \n",
    "        if dataset_id:\n",
    "            iteration.log_dataset(dataset_id=dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914d539c",
   "metadata": {},
   "source": [
    "#### 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28fec2bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:57.194502Z",
     "start_time": "2024-01-04T13:03:57.102103Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "parameters = {'n_neighbors': 5, 'metric': 'minkowski', 'algorithm': 'auto'}\n",
    "model = KNeighborsClassifier(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "metrics = {\n",
    "    'accuracy': round(accuracy_score(y_test, prediction), 3),\n",
    "    'precision': round(precision_score(y_test, prediction, average='macro'), 3),\n",
    "    'recall': round(recall_score(y_test, prediction, average='macro'), 3),\n",
    "    'f1': round(f1_score(y_test, prediction, average='macro'), 3)\n",
    "}\n",
    "\n",
    "log_single_iteration(iteration_name='KNN v1',\n",
    "                     model_name='KNN',\n",
    "                     model_params=parameters,\n",
    "                     metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1134b16",
   "metadata": {},
   "source": [
    "#### 2nd iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6333f5f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:57.567382Z",
     "start_time": "2024-01-04T13:03:57.473379Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "parameters = {'n_neighbors': 15, 'metric': 'cosine', 'algorithm': 'auto'}\n",
    "model = KNeighborsClassifier(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test.values)\n",
    "metrics = {\n",
    "    'accuracy': round(accuracy_score(y_test, prediction), 3),\n",
    "    'precision': round(precision_score(y_test, prediction, average='macro'), 3),\n",
    "    'recall': round(recall_score(y_test, prediction, average='macro'), 3),\n",
    "    'f1': round(f1_score(y_test, prediction, average='macro'), 3)\n",
    "}\n",
    "with open('../test_files/knn_v2.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "log_single_iteration(iteration_name='KNN v2',\n",
    "                     model_name='KNN',\n",
    "                     model_params=parameters,\n",
    "                     metrics=metrics,\n",
    "                     model_path=os.path.abspath('../test_files/knn_v2.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88cdc7f",
   "metadata": {},
   "source": [
    "#### 3rd iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25c67c4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:57.953284Z",
     "start_time": "2024-01-04T13:03:57.928765Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors': 45, 'metric': 'manhattan', 'algorithm': 'ball_tree'}\n",
    "model = KNeighborsClassifier(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "metrics = {\n",
    "    'accuracy': round(accuracy_score(y_test, prediction), 3),\n",
    "    'precision': round(precision_score(y_test, prediction, average='macro'), 3),\n",
    "    'recall': round(recall_score(y_test, prediction, average='macro'), 3),\n",
    "    'f1': round(f1_score(y_test, prediction, average='macro'), 3)\n",
    "}\n",
    "\n",
    "log_single_iteration(iteration_name='KNN v3',\n",
    "                     model_name='KNN',\n",
    "                     model_params=parameters,\n",
    "                     metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69b21a",
   "metadata": {},
   "source": [
    "### Creating iterations with dataset\n",
    "\n",
    "MLOps datasets are stored in a separate tab. They are not actual data, rather than URL or local path attachments to actual data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313fe6f0",
   "metadata": {},
   "source": [
    "#### Create a dataset from library (from website is better tho) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1dcf835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:58.835151Z",
     "start_time": "2024-01-04T13:03:58.563349Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlops.tracking import create_dataset\n",
    "\n",
    "dataset_v1 = create_dataset(\n",
    "    dataset_name=\"Iris dataset\",\n",
    "    path_to_dataset=\"https://www.kaggle.com/datasets/uciml/iris\",\n",
    "    dataset_description=\"Famous Iris species dataset\",\n",
    "    tags=\"iris,kaggle,classification,multiclass\",\n",
    "    version=\"1.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f051ceae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:59.146558Z",
     "start_time": "2024-01-04T13:03:58.836153Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_v2 = create_dataset(\n",
    "    dataset_name=\"Iris dataset\",\n",
    "    path_to_dataset=\"https://www.kaggle.com/datasets/arshid/iris-flower-dataset\",\n",
    "    dataset_description=\"Famous Iris species dataset\",\n",
    "    tags=\"iris,kaggle,classification,multiclass\",\n",
    "    version=\"2.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9804bc",
   "metadata": {},
   "source": [
    "#### Create a separable experiment for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "600f7970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:03:59.997135Z",
     "start_time": "2024-01-04T13:03:59.970137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Active experiment set to: 6596acbf7826134dfca22757'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = create_experiment(\n",
    "    name=\"Iterations with dataset\",\n",
    "    description=\"Iterations with dataset showcase\"\n",
    ")\n",
    "\n",
    "set_active_experiment(experiment_id=experiment['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9718b",
   "metadata": {},
   "source": [
    "#### Log iterations with different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "343bca7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:00.803925Z",
     "start_time": "2024-01-04T13:04:00.650701Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {'n_estimators': 100, 'max_depth': 5}\n",
    "model = RandomForestClassifier(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "metrics = {\n",
    "    'accuracy': round(accuracy_score(y_test, prediction), 3),\n",
    "    'precision': round(precision_score(y_test, prediction, average='macro'), 3),\n",
    "    'recall': round(recall_score(y_test, prediction, average='macro'), 3),\n",
    "    'f1': round(f1_score(y_test, prediction, average='macro'), 3)\n",
    "}\n",
    "\n",
    "log_single_iteration(iteration_name='RF with dataset v1',\n",
    "                     model_name='Random Forest',\n",
    "                     model_params=parameters,\n",
    "                     metrics=metrics,\n",
    "                     dataset_id=dataset_v1['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "576ad9b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:01.555185Z",
     "start_time": "2024-01-04T13:04:01.114931Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': 500, 'max_depth': 10}\n",
    "model = RandomForestClassifier(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "metrics = {\n",
    "    'accuracy': round(accuracy_score(y_test, prediction), 3),\n",
    "    'precision': round(precision_score(y_test, prediction, average='macro'), 3),\n",
    "    'recall': round(recall_score(y_test, prediction, average='macro'), 3),\n",
    "    'f1': round(f1_score(y_test, prediction, average='macro'), 3)\n",
    "}\n",
    "\n",
    "log_single_iteration(iteration_name='RF with dataset v2',\n",
    "                     model_name='Random Forest',\n",
    "                     model_params=parameters,\n",
    "                     metrics=metrics,\n",
    "                     dataset_id=dataset_v2['_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09763226",
   "metadata": {},
   "source": [
    "### Creating iterations with Interactive Charts\n",
    "\n",
    "MLOps allows to create interactive charts from data that can be displayed on site with iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49cead0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:01.975113Z",
     "start_time": "2024-01-04T13:04:01.952115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Active experiment set to: 6596acc17826134dfca2275a'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = create_experiment(\n",
    "    name=\"Iterations with charts\",\n",
    "    description=\"Iterations with charts showcase\"\n",
    ")\n",
    "\n",
    "set_active_experiment(experiment_id=experiment['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd53dc6",
   "metadata": {},
   "source": [
    "#### Simple pyTorch neural network model\n",
    "\n",
    "For that purpose, let's create simple pyTorch NN model for Iris classification and based on that visualize learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c22d983b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.033315Z",
     "start_time": "2024-01-04T13:04:02.335759Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "BATCH_SIZE=32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fe50fac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.048632Z",
     "start_time": "2024-01-04T13:04:04.035328Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BaselineNN(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17b74d43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.064646Z",
     "start_time": "2024-01-04T13:04:04.050632Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MonitoredModelWrapper:\n",
    "    \"\"\"\n",
    "    A wrapper for monitored model that does not have .predict() method from dataframe (like scikit-learn API).\n",
    "    In this example, we will use a PyTorch model for Iris classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: object):\n",
    "        self.model: object = model\n",
    "\n",
    "    def predict(self, data: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Predicts target values from input pandas dataframe.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): Input data.\n",
    "\n",
    "        Returns:\n",
    "            np.array: Predicted target values.\n",
    "        \"\"\"\n",
    "        X_tensor = torch.tensor(data.values, dtype=torch.float32)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            y_logits = self.model(X_tensor)\n",
    "            y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "        return y_pred.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde26e9",
   "metadata": {},
   "source": [
    "#### 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60405891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.563513Z",
     "start_time": "2024-01-04T13:04:04.066645Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "HIDDEN_UNITS=10\n",
    "LEARNING_RATE=0.01\n",
    "\n",
    "model = BaselineNN(input_shape=X_train.shape[1],\n",
    "                   hidden_units=HIDDEN_UNITS,\n",
    "                   output_shape=pd.Series(y).nunique())\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a729a36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.578513Z",
     "start_time": "2024-01-04T13:04:04.564513Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def train_model(model, epochs: int = 10):\n",
    "    \"\"\"\n",
    "    Util function for training pyTorch model\n",
    "    \n",
    "    Args:\n",
    "        model: torch model instance\n",
    "        epochs (int): number of epochs\n",
    "    \"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "    \n",
    "    ## Training\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", unit=\"epoch\", total=epochs):\n",
    "        \n",
    "        train_loss, train_acc = 0, 0\n",
    "        \n",
    "        for batch, (X, y) in enumerate(train_loader):\n",
    "            model.train() \n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss\n",
    "            train_acc += accuracy_score(torch.softmax(y_pred, dim=1).argmax(dim=1), y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "\n",
    "        ## Validation\n",
    "        val_loss, val_acc = 0, 0 \n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for X, y in test_loader:\n",
    "                val_pred = model(X)\n",
    "                val_loss += loss_fn(val_pred, y)\n",
    "                val_acc += accuracy_score(torch.softmax(val_pred, dim=1).argmax(dim=1), y)\n",
    "\n",
    "            val_loss /= len(test_loader)\n",
    "            val_acc /= len(test_loader)\n",
    "\n",
    "        print(f\"Epoch: {epoch} | Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}% | Val loss: {val_loss:.5f}, Val acc: {val_acc:.2f}%\")\n",
    "        train_losses.append(round(train_loss.item(), 3))\n",
    "        train_accs.append(round(train_acc.item(), 3))\n",
    "        val_losses.append(round(val_loss.item(), 3))\n",
    "        val_accs.append(round(val_acc.item(), 3))\n",
    "        \n",
    "    return train_losses, train_accs, val_losses, val_accs\n",
    "\n",
    "\n",
    "def evaluate_model(model):\n",
    "    \"\"\"\n",
    "    Util function for evaluating pyTorch model, i.e. returning predictions\n",
    "    \n",
    "    Args:\n",
    "        model: torch model instance\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        y_logits = model(X_test_tensor)\n",
    "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "        \n",
    "    return y_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f51db78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.672029Z",
     "start_time": "2024-01-04T13:04:04.579515Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03804b8fe13475d91e483900a515d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 1.17898 | Train acc: 0.34% | Val loss: 0.99695, Val acc: 0.72%\n",
      "Epoch: 1 | Train loss: 1.04611 | Train acc: 0.42% | Val loss: 1.00933, Val acc: 0.36%\n",
      "Epoch: 2 | Train loss: 0.97937 | Train acc: 0.57% | Val loss: 0.94357, Val acc: 0.64%\n",
      "Epoch: 3 | Train loss: 0.91316 | Train acc: 0.72% | Val loss: 0.86912, Val acc: 0.64%\n",
      "Epoch: 4 | Train loss: 0.85918 | Train acc: 0.78% | Val loss: 0.80718, Val acc: 0.81%\n",
      "Epoch: 5 | Train loss: 0.80410 | Train acc: 0.74% | Val loss: 0.75446, Val acc: 0.72%\n",
      "Epoch: 6 | Train loss: 0.76311 | Train acc: 0.66% | Val loss: 0.70279, Val acc: 0.72%\n",
      "Epoch: 7 | Train loss: 0.73427 | Train acc: 0.64% | Val loss: 0.65751, Val acc: 0.72%\n",
      "Epoch: 8 | Train loss: 0.68466 | Train acc: 0.68% | Val loss: 0.62150, Val acc: 0.76%\n",
      "Epoch: 9 | Train loss: 0.62407 | Train acc: 0.76% | Val loss: 0.59265, Val acc: 0.93%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "train_losses, train_accs, val_losses, val_accs = train_model(model, epochs=EPOCHS)\n",
    "y_pred = evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71ad7ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.719027Z",
     "start_time": "2024-01-04T13:04:04.674027Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'batch_size': BATCH_SIZE, 'epochs': EPOCHS, 'learning_rate': LEARNING_RATE}\n",
    "metrics = {\n",
    "    'train_loss': round(train_losses[-1], 3),\n",
    "    'train_acc': round(train_accs[-1], 3),\n",
    "    'val_loss': round(val_losses[-1], 3),\n",
    "    'val_acc': round(val_accs[-1], 3)\n",
    "}\n",
    "torch_monitored = MonitoredModelWrapper(model=model)\n",
    "with open('../test_files/torch_model.pkl', 'wb') as f:\n",
    "    pickle.dump(torch_monitored, f)\n",
    "\n",
    "with start_iteration(iteration_name='NN v1') as iteration:\n",
    "    iteration.log_parameters(parameters=parameters)\n",
    "    iteration.log_metrics(metrics=metrics)\n",
    "    iteration.log_dataset(dataset_id=dataset_v1['_id'])\n",
    "    iteration.log_path_to_model(os.path.abspath('../test_files/torch_model.pkl'))\n",
    "    \n",
    "    iteration.log_chart(\n",
    "        chart_name=\"Loss\", chart_type=\"line\",\n",
    "        x_data=[[i for i in range(len(train_losses))]],\n",
    "        y_data=[train_losses, val_losses],\n",
    "        y_data_names=['training loss', 'validation loss'],\n",
    "        x_label=\"epochs\", y_label=\"Loss\", \n",
    "        chart_title='Training vs validation loss',\n",
    "        comparable=True)\n",
    "    \n",
    "    iteration.log_chart(\n",
    "        chart_name=\"Accuracy\", chart_type=\"line\",\n",
    "        x_data=[[i for i in range(len(train_losses))]],\n",
    "        y_data=[train_accs, val_accs],\n",
    "        y_data_names=['training acc', 'validation acc'],\n",
    "        x_label=\"epochs\", y_label=\"Loss\", \n",
    "        chart_title='Training vs validation accuracy',\n",
    "        comparable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c068376c",
   "metadata": {},
   "source": [
    "#### 2nd iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "720d3987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.734029Z",
     "start_time": "2024-01-04T13:04:04.721027Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "HIDDEN_UNITS=100\n",
    "LEARNING_RATE=0.001\n",
    "\n",
    "model = BaselineNN(input_shape=X_train.shape[1],\n",
    "                   hidden_units=HIDDEN_UNITS,\n",
    "                   output_shape=pd.Series(y).nunique())\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ede04ef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.827550Z",
     "start_time": "2024-01-04T13:04:04.735034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e469f1a3744a96ad47b54245880397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 1.13291 | Train acc: 0.35% | Val loss: 1.04898, Val acc: 0.64%\n",
      "Epoch: 1 | Train loss: 1.01002 | Train acc: 0.66% | Val loss: 0.97090, Val acc: 0.72%\n",
      "Epoch: 2 | Train loss: 0.95823 | Train acc: 0.70% | Val loss: 0.92601, Val acc: 0.72%\n",
      "Epoch: 3 | Train loss: 0.96286 | Train acc: 0.64% | Val loss: 0.89495, Val acc: 0.72%\n",
      "Epoch: 4 | Train loss: 0.93175 | Train acc: 0.64% | Val loss: 0.86333, Val acc: 0.72%\n",
      "Epoch: 5 | Train loss: 0.88424 | Train acc: 0.66% | Val loss: 0.83263, Val acc: 0.72%\n",
      "Epoch: 6 | Train loss: 0.85016 | Train acc: 0.66% | Val loss: 0.80585, Val acc: 0.72%\n",
      "Epoch: 7 | Train loss: 0.82462 | Train acc: 0.64% | Val loss: 0.78180, Val acc: 0.80%\n",
      "Epoch: 8 | Train loss: 0.79088 | Train acc: 0.91% | Val loss: 0.76002, Val acc: 0.88%\n",
      "Epoch: 9 | Train loss: 0.75958 | Train acc: 0.91% | Val loss: 0.73725, Val acc: 0.86%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "train_losses, train_accs, val_losses, val_accs = train_model(model, epochs=EPOCHS)\n",
    "y_pred = evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cfb9081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.859065Z",
     "start_time": "2024-01-04T13:04:04.829549Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'batch_size': BATCH_SIZE, 'epochs': EPOCHS, 'learning_rate': LEARNING_RATE}\n",
    "metrics = {\n",
    "    'train_loss': round(train_losses[-1], 3),\n",
    "    'train_acc': round(train_accs[-1], 3),\n",
    "    'val_loss': round(val_losses[-1], 3),\n",
    "    'val_acc': round(val_accs[-1], 3)\n",
    "}\n",
    "\n",
    "with start_iteration(iteration_name='NN v2') as iteration:\n",
    "    iteration.log_parameters(parameters=parameters)\n",
    "    iteration.log_metrics(metrics=metrics)\n",
    "    iteration.log_dataset(dataset_id=dataset_v1['_id'])\n",
    "    \n",
    "    iteration.log_chart(\n",
    "        chart_name=\"Loss\", chart_type=\"line\",\n",
    "        x_data=[[i for i in range(len(train_losses))]],\n",
    "        y_data=[train_losses, val_losses],\n",
    "        y_data_names=['training loss', 'validation loss'],\n",
    "        x_label=\"epochs\", y_label=\"Loss\", \n",
    "        chart_title='Training vs validation loss',\n",
    "        comparable=True)\n",
    "    \n",
    "    iteration.log_chart(\n",
    "        chart_name=\"Accuracy\", chart_type=\"line\",\n",
    "        x_data=[[i for i in range(len(train_losses))]],\n",
    "        y_data=[train_accs, val_accs],\n",
    "        y_data_names=['training acc', 'validation acc'],\n",
    "        x_label=\"epochs\", y_label=\"Loss\", \n",
    "        chart_title='Training vs validation accuracy',\n",
    "        comparable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd674434",
   "metadata": {},
   "source": [
    "### Creating iterations with Image Charts\n",
    "\n",
    "MLOps alows not only to log interactive charts, but also presaved charts from images (i.e. from matplotlib or seaborn library).\n",
    "\n",
    "**<font color='red'>Attention!</font>**<br>\n",
    "**Unfortunately, this feature does not work on Linux/macOS system.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "506f7d11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:04.891068Z",
     "start_time": "2024-01-04T13:04:04.860066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Active experiment set to: 6596acc47826134dfca22761'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = create_experiment(\n",
    "    name=\"Iterations with image charts\",\n",
    "    description=\"Iterations with image charts showcase\"\n",
    ")\n",
    "\n",
    "set_active_experiment(experiment_id=experiment['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86961f2b",
   "metadata": {},
   "source": [
    "#### Example image charts iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37ab8c67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:05.576525Z",
     "start_time": "2024-01-04T13:04:05.553828Z"
    }
   },
   "outputs": [],
   "source": [
    "with start_iteration(\"Iteration with image v1\") as iteration:\n",
    "    iteration.log_parameter(\"n_estimators\", 150)\n",
    "    iteration.log_metric(\"RMSE\", 0.9)\n",
    "    iteration.log_metric(\"MAE\", 0.45)\n",
    "    iteration.log_image_chart(name=\"Image chart 1\", \n",
    "                              image_path='../test_files/plot-1.png')\n",
    "    iteration.log_image_chart(name=\"Image chart 2\", \n",
    "                              image_path='../test_files/plot-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b1dbc3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:06.410696Z",
     "start_time": "2024-01-04T13:04:06.387690Z"
    }
   },
   "outputs": [],
   "source": [
    "with start_iteration(\"Iteration with image v2\") as iteration:\n",
    "    iteration.log_parameter(\"n_estimators\", 225)\n",
    "    iteration.log_metric(\"RMSE\", 0.8)\n",
    "    iteration.log_metric(\"MAE\", 0.41)\n",
    "    iteration.log_image_chart(name=\"Image chart 3\", \n",
    "                              image_path='../test_files/plot-3.png')\n",
    "    iteration.log_image_chart(name=\"Image chart 4\", \n",
    "                              image_path='../test_files/plot-4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec09632",
   "metadata": {},
   "source": [
    "## Monitoring module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad13e8",
   "metadata": {},
   "source": [
    "### Creating a monitored model\n",
    "\n",
    "Creating a monitored model takes place from the application side. You can select a model from the grid (one that have actual `Model path`, i.e. one of the KNN or NN) and select **Create model** button. Please, name it **Showcase model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31250ff",
   "metadata": {},
   "source": [
    "### Send predictions to the monitored model\n",
    "\n",
    "When the monitored model is ready, you can send prediction requests to the model with pd.DataFrame as an input data. <br> Prediction is made as a batch prediction for the whole DataFrame, below you can see comparison between single batch prediction for the whole dataframe vs many instance predictions for each sample from DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56fb577",
   "metadata": {},
   "source": [
    "#### Batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0ce4849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:25.882747Z",
     "start_time": "2024-01-04T13:04:25.835118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.02651524543762207 seconds\n"
     ]
    }
   ],
   "source": [
    "from mlops.monitoring import send_prediction\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "_ = send_prediction(\n",
    "    model_name='Showcase model',\n",
    "    data=X_test\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66111ec",
   "metadata": {},
   "source": [
    "#### Instance predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6087d9d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:31.515321Z",
     "start_time": "2024-01-04T13:04:29.265507Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2.232327699661255 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for idx, val in X_test.iterrows():\n",
    "    _ = send_prediction(\n",
    "        model_name='Showcase model',\n",
    "        data=pd.DataFrame([val])\n",
    "    )\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8647f",
   "metadata": {},
   "source": [
    "### Get predictions from the monitored model\n",
    "\n",
    "You can also get predictions from the monitored model afterwards, i.e. after annotating actual value from the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1537472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:34.654693Z",
     "start_time": "2024-01-04T13:04:34.611447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction_date</th>\n",
       "      <th>input_data</th>\n",
       "      <th>prediction</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6596acd97826134dfca22769</td>\n",
       "      <td>2024-01-04T14:04:25.851000</td>\n",
       "      <td>{'sepal-length': 5.1, 'sepal-width': 3.7, 'pet...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6596acd97826134dfca2276a</td>\n",
       "      <td>2024-01-04T14:04:25.851000</td>\n",
       "      <td>{'sepal-length': 5.0, 'sepal-width': 3.4, 'pet...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6596acd97826134dfca2276b</td>\n",
       "      <td>2024-01-04T14:04:25.851000</td>\n",
       "      <td>{'sepal-length': 5.0, 'sepal-width': 3.2, 'pet...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6596acd97826134dfca2276c</td>\n",
       "      <td>2024-01-04T14:04:25.851000</td>\n",
       "      <td>{'sepal-length': 5.1, 'sepal-width': 3.3, 'pet...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6596acd97826134dfca2276d</td>\n",
       "      <td>2024-01-04T14:04:25.851000</td>\n",
       "      <td>{'sepal-length': 6.4, 'sepal-width': 2.8, 'pet...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6596acdf7826134dfca227fa</td>\n",
       "      <td>2024-01-04T14:04:31.347000</td>\n",
       "      <td>{'sepal-length': 5.5, 'sepal-width': 2.3, 'pet...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6596acdf7826134dfca227fb</td>\n",
       "      <td>2024-01-04T14:04:31.382000</td>\n",
       "      <td>{'sepal-length': 4.6, 'sepal-width': 3.6, 'pet...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6596acdf7826134dfca227fc</td>\n",
       "      <td>2024-01-04T14:04:31.417000</td>\n",
       "      <td>{'sepal-length': 7.1, 'sepal-width': 3.0, 'pet...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6596acdf7826134dfca227fd</td>\n",
       "      <td>2024-01-04T14:04:31.452000</td>\n",
       "      <td>{'sepal-length': 6.3, 'sepal-width': 3.4, 'pet...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6596acdf7826134dfca227fe</td>\n",
       "      <td>2024-01-04T14:04:31.486000</td>\n",
       "      <td>{'sepal-length': 6.0, 'sepal-width': 3.0, 'pet...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id             prediction_date  \\\n",
       "0    6596acd97826134dfca22769  2024-01-04T14:04:25.851000   \n",
       "1    6596acd97826134dfca2276a  2024-01-04T14:04:25.851000   \n",
       "2    6596acd97826134dfca2276b  2024-01-04T14:04:25.851000   \n",
       "3    6596acd97826134dfca2276c  2024-01-04T14:04:25.851000   \n",
       "4    6596acd97826134dfca2276d  2024-01-04T14:04:25.851000   \n",
       "..                        ...                         ...   \n",
       "145  6596acdf7826134dfca227fa  2024-01-04T14:04:31.347000   \n",
       "146  6596acdf7826134dfca227fb  2024-01-04T14:04:31.382000   \n",
       "147  6596acdf7826134dfca227fc  2024-01-04T14:04:31.417000   \n",
       "148  6596acdf7826134dfca227fd  2024-01-04T14:04:31.452000   \n",
       "149  6596acdf7826134dfca227fe  2024-01-04T14:04:31.486000   \n",
       "\n",
       "                                            input_data  prediction actual  \n",
       "0    {'sepal-length': 5.1, 'sepal-width': 3.7, 'pet...         0.0   None  \n",
       "1    {'sepal-length': 5.0, 'sepal-width': 3.4, 'pet...         0.0   None  \n",
       "2    {'sepal-length': 5.0, 'sepal-width': 3.2, 'pet...         0.0   None  \n",
       "3    {'sepal-length': 5.1, 'sepal-width': 3.3, 'pet...         0.0   None  \n",
       "4    {'sepal-length': 6.4, 'sepal-width': 2.8, 'pet...         2.0   None  \n",
       "..                                                 ...         ...    ...  \n",
       "145  {'sepal-length': 5.5, 'sepal-width': 2.3, 'pet...         1.0   None  \n",
       "146  {'sepal-length': 4.6, 'sepal-width': 3.6, 'pet...         0.0   None  \n",
       "147  {'sepal-length': 7.1, 'sepal-width': 3.0, 'pet...         2.0   None  \n",
       "148  {'sepal-length': 6.3, 'sepal-width': 3.4, 'pet...         2.0   None  \n",
       "149  {'sepal-length': 6.0, 'sepal-width': 3.0, 'pet...         2.0   None  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlops.monitoring import get_model_by_name\n",
    "\n",
    "pd.DataFrame(get_model_by_name(model_name='Showcase model')['predictions_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e1222c",
   "metadata": {},
   "source": [
    "## Email alerts module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a313a73",
   "metadata": {},
   "source": [
    "### Setup [MailGun](https://www.mailgun.com/) variables\n",
    "\n",
    "MLOps email alerts module is integrated with [MailGun](https://www.mailgun.com/). So as to receive email alerts after iteration or sending a prediction, you have to register at MailGun and provide your data as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a552aab1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T13:04:36.622646Z",
     "start_time": "2024-01-04T13:04:36.609646Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlops.config.config import settings\n",
    "\n",
    "settings.set_mailgun_domain('your-mailgun-domain')\n",
    "settings.set_mailgun_api_key('your-mailgun-api-key')\n",
    "settings.set_user_email('your-email') \n",
    "settings.set_send_emails_flag(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.812px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
