{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca79d2e5",
   "metadata": {},
   "source": [
    "# mlops-ai library showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5642c63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:11.355247Z",
     "start_time": "2023-11-30T16:27:11.350068Z"
    }
   },
   "outputs": [],
   "source": [
    "# import sys, os\n",
    "# sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af5c39a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:15.741611Z",
     "start_time": "2023-11-30T16:27:15.726085Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install mlops-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68677b74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:17.126574Z",
     "start_time": "2023-11-30T16:27:16.052863Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: mlops-ai\n"
     ]
    }
   ],
   "source": [
    "!pip show mlops-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67845a03",
   "metadata": {},
   "source": [
    "## Creating a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8837e48b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:17.266358Z",
     "start_time": "2023-11-30T16:27:17.128574Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlops.tracking import create_project, get_project, set_active_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0383482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:17.281591Z",
     "start_time": "2023-11-30T16:27:17.268358Z"
    }
   },
   "outputs": [],
   "source": [
    "project = create_project(\n",
    "    title=\"Iris classification\", \n",
    "    description=\"This project is focused on three Iris species multi-classification\",\n",
    "    status='in_progress'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e58e117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:17.699595Z",
     "start_time": "2023-11-30T16:27:17.686082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Active project set to: 6568b7e58818cbb8a06e3cb6'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_active_project(project_id=project['_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3601b",
   "metadata": {},
   "source": [
    "## Creating a first experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de895e7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:18.167470Z",
     "start_time": "2023-11-30T16:27:18.163948Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlops.tracking import create_experiment, get_experiment, set_active_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2da3b238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:18.371124Z",
     "start_time": "2023-11-30T16:27:18.359103Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = create_experiment(\n",
    "    # project_id=project['_id'] don't have to pass, since we have set active project\n",
    "    name=\"KNN models\",\n",
    "    description=\"Experimenting with different KNN models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b7f03de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:18.558011Z",
     "start_time": "2023-11-30T16:27:18.540970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Active experiment set to: 6568b7e68818cbb8a06e3cb7'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_active_experiment(experiment_id=experiment['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda257ae",
   "metadata": {},
   "source": [
    "## Creating multiple iterations for our experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1f31a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:34.910848Z",
     "start_time": "2023-11-30T16:27:33.368516Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/TripathiAshutosh/dataset/main/iris.csv'\n",
    "df = pd.read_csv(filepath_or_buffer=url, sep=',')\n",
    "y = LabelEncoder().fit_transform(df['class'])\n",
    "X = df.drop(columns=['class'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify = y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd39834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:34.926575Z",
     "start_time": "2023-11-30T16:27:34.912851Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlops.tracking import start_iteration\n",
    "\n",
    "\n",
    "def log_single_iteration(iteration_name: str, model_name: str,\n",
    "                         model_params: dict = None,\n",
    "                         metrics: dict = None,\n",
    "                         model_path: str = None,\n",
    "                         dataset_id: str = None,\n",
    "                         interactive_charts: list = None):\n",
    "    \"\"\"\n",
    "    Util function for creating single mlops iteration.\n",
    "    \n",
    "    Args:\n",
    "        iteration_name (str): name of the whole iteration\n",
    "        model_name (str): name of the logged model\n",
    "        model_params (dict): parameters of model\n",
    "        metrics (dict): model metrics\n",
    "        model_path (str): path to saved model file\n",
    "        dataset_id (str): id to dataset from datasets tab\n",
    "    \"\"\"\n",
    "    with start_iteration(iteration_name=iteration_name) as iteration:\n",
    "        if model_params:\n",
    "            iteration.log_parameters(parameters=model_params)\n",
    "            \n",
    "        if metrics:\n",
    "            iteration.log_metrics(metrics=metrics)\n",
    "            \n",
    "        if model_path:\n",
    "            iteration.log_path_to_model(path_to_model=model_path)\n",
    "        \n",
    "        if dataset_id:\n",
    "            iteration.log_dataset(dataset_id=dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914d539c",
   "metadata": {},
   "source": [
    "### 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28fec2bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:35.964698Z",
     "start_time": "2023-11-30T16:27:35.856172Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "parameters = {'n_neighbors': 5, 'metric': 'minkowski', 'algorithm': 'auto'}\n",
    "model = KNeighborsClassifier(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "metrics = {\n",
    "    'accuracy': round(accuracy_score(y_test, prediction), 3),\n",
    "    'precision': round(precision_score(y_test, prediction, average='macro'), 3),\n",
    "    'recall': round(recall_score(y_test, prediction, average='macro'), 3),\n",
    "    'f1': round(f1_score(y_test, prediction, average='macro'), 3)\n",
    "}\n",
    "\n",
    "log_single_iteration(iteration_name='KNN v1',\n",
    "                     model_name='KNN',\n",
    "                     model_params=parameters,\n",
    "                     metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1134b16",
   "metadata": {},
   "source": [
    "### 2nd iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6333f5f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:36.771519Z",
     "start_time": "2023-11-30T16:27:36.688470Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "parameters = {'n_neighbors': 15, 'metric': 'cosine', 'algorithm': 'auto'}\n",
    "model = KNeighborsClassifier(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "metrics = {\n",
    "    'accuracy': round(accuracy_score(y_test, prediction), 3),\n",
    "    'precision': round(precision_score(y_test, prediction, average='macro'), 3),\n",
    "    'recall': round(recall_score(y_test, prediction, average='macro'), 3),\n",
    "    'f1': round(f1_score(y_test, prediction, average='macro'), 3)\n",
    "}\n",
    "with open('../test_files/knn_v2.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "log_single_iteration(iteration_name='KNN v2',\n",
    "                     model_name='KNN',\n",
    "                     model_params=parameters,\n",
    "                     metrics=metrics,\n",
    "                     model_path=os.path.abspath('../test_files/knn_v2.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88cdc7f",
   "metadata": {},
   "source": [
    "### 3rd iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c67c4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:37.333181Z",
     "start_time": "2023-11-30T16:27:37.300141Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors': 45, 'metric': 'manhattan', 'algorithm': 'ball_tree'}\n",
    "model = KNeighborsClassifier(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "metrics = {\n",
    "    'accuracy': round(accuracy_score(y_test, prediction), 3),\n",
    "    'precision': round(precision_score(y_test, prediction, average='macro'), 3),\n",
    "    'recall': round(recall_score(y_test, prediction, average='macro'), 3),\n",
    "    'f1': round(f1_score(y_test, prediction, average='macro'), 3)\n",
    "}\n",
    "\n",
    "log_single_iteration(iteration_name='KNN v3',\n",
    "                     model_name='KNN',\n",
    "                     model_params=parameters,\n",
    "                     metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69b21a",
   "metadata": {},
   "source": [
    "## Creating iterations with dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1bc023",
   "metadata": {},
   "source": [
    "### Create a separable experiment for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42ef2c6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:38.209052Z",
     "start_time": "2023-11-30T16:27:38.178477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Active experiment set to: 6568b7fa8818cbb8a06e3cbb'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = create_experiment(\n",
    "    name=\"Iterations with dataset\",\n",
    "    description=\"Iterations with dataset showcase\"\n",
    ")\n",
    "\n",
    "set_active_experiment(experiment_id=experiment['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313fe6f0",
   "metadata": {},
   "source": [
    "### Create a dataset from library (from website is better tho) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1dcf835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:39.359545Z",
     "start_time": "2023-11-30T16:27:38.953522Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlops.tracking import create_dataset\n",
    "\n",
    "dataset_v1 = create_dataset(\n",
    "    dataset_name=\"Iris dataset\",\n",
    "    path_to_dataset=\"https://www.kaggle.com/datasets/uciml/iris\",\n",
    "    dataset_description=\"Famous Iris species dataset\",\n",
    "    tags=\"iris,kaggle,classification,multiclass\",\n",
    "    version=\"1.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f051ceae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:39.791840Z",
     "start_time": "2023-11-30T16:27:39.360534Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_v2 = create_dataset(\n",
    "    dataset_name=\"Iris dataset\",\n",
    "    path_to_dataset=\"https://www.kaggle.com/datasets/arshid/iris-flower-dataset\",\n",
    "    dataset_description=\"Famous Iris species dataset\",\n",
    "    tags=\"iris,kaggle,classification,multiclass\",\n",
    "    version=\"2.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9718b",
   "metadata": {},
   "source": [
    "### Log iterations with different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "343bca7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:40.522785Z",
     "start_time": "2023-11-30T16:27:40.355900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {'n_estimators': 100, 'max_depth': 5}\n",
    "model = RandomForestClassifier(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "metrics = {\n",
    "    'accuracy': round(accuracy_score(y_test, prediction), 3),\n",
    "    'precision': round(precision_score(y_test, prediction, average='macro'), 3),\n",
    "    'recall': round(recall_score(y_test, prediction, average='macro'), 3),\n",
    "    'f1': round(f1_score(y_test, prediction, average='macro'), 3)\n",
    "}\n",
    "\n",
    "log_single_iteration(iteration_name='RF with dataset v1',\n",
    "                     model_name='Random Forest',\n",
    "                     model_params=parameters,\n",
    "                     metrics=metrics,\n",
    "                     dataset_id=dataset_v1['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "576ad9b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:41.473491Z",
     "start_time": "2023-11-30T16:27:41.027069Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': 500, 'max_depth': 10}\n",
    "model = RandomForestClassifier(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "metrics = {\n",
    "    'accuracy': round(accuracy_score(y_test, prediction), 3),\n",
    "    'precision': round(precision_score(y_test, prediction, average='macro'), 3),\n",
    "    'recall': round(recall_score(y_test, prediction, average='macro'), 3),\n",
    "    'f1': round(f1_score(y_test, prediction, average='macro'), 3)\n",
    "}\n",
    "\n",
    "log_single_iteration(iteration_name='RF with dataset v2',\n",
    "                     model_name='Random Forest',\n",
    "                     model_params=parameters,\n",
    "                     metrics=metrics,\n",
    "                     dataset_id=dataset_v2['_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09763226",
   "metadata": {},
   "source": [
    "## Creating iterations with Interactive Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49cead0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:42.284965Z",
     "start_time": "2023-11-30T16:27:42.260736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Active experiment set to: 6568b7fe8818cbb8a06e3cc0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = create_experiment(\n",
    "    name=\"Iterations with charts\",\n",
    "    description=\"Iterations with charts showcase\"\n",
    ")\n",
    "\n",
    "set_active_experiment(experiment_id=experiment['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd53dc6",
   "metadata": {},
   "source": [
    "### simple pyTorch neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c22d983b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:44.928614Z",
     "start_time": "2023-11-30T16:27:43.232411Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "BATCH_SIZE=32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fe50fac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:45.284080Z",
     "start_time": "2023-11-30T16:27:45.278023Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BaselineNN(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17b74d43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:45.657408Z",
     "start_time": "2023-11-30T16:27:45.651385Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MonitoredModelWrapper:\n",
    "    \"\"\"\n",
    "    A wrapper for monitored model that does not have .predict() method from dataframe (like scikit-learn API).\n",
    "    In this example, we will use a PyTorch model for Iris classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: object):\n",
    "        self.model: object = model\n",
    "\n",
    "    def predict(self, data: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Predicts target values from input pandas dataframe.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): Input data.\n",
    "\n",
    "        Returns:\n",
    "            np.array: Predicted target values.\n",
    "        \"\"\"\n",
    "        X_tensor = torch.tensor(data.values, dtype=torch.float32)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            y_logits = self.model(X_tensor)\n",
    "            y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "        return y_pred.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde26e9",
   "metadata": {},
   "source": [
    "### 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60405891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:46.326154Z",
     "start_time": "2023-11-30T16:27:46.308112Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "HIDDEN_UNITS=10\n",
    "LEARNING_RATE=0.01\n",
    "\n",
    "model = BaselineNN(input_shape=X_train.shape[1],\n",
    "                   hidden_units=HIDDEN_UNITS,\n",
    "                   output_shape=pd.Series(y).nunique())\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a729a36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:46.870085Z",
     "start_time": "2023-11-30T16:27:46.718058Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def train_model(model, epochs: int = 10):\n",
    "    \"\"\"\n",
    "    Util function for training pyTorch model\n",
    "    \n",
    "    Args:\n",
    "        model: torch model instance\n",
    "        epochs (int): number of epochs\n",
    "    \"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "    \n",
    "    ## Training\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", unit=\"epoch\", total=epochs):\n",
    "        \n",
    "        train_loss, train_acc = 0, 0\n",
    "        \n",
    "        for batch, (X, y) in enumerate(train_loader):\n",
    "            model.train() \n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss\n",
    "            train_acc += accuracy_score(torch.softmax(y_pred, dim=1).argmax(dim=1), y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "\n",
    "        ## Validation\n",
    "        val_loss, val_acc = 0, 0 \n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for X, y in test_loader:\n",
    "                val_pred = model(X)\n",
    "                val_loss += loss_fn(val_pred, y)\n",
    "                val_acc += accuracy_score(torch.softmax(val_pred, dim=1).argmax(dim=1), y)\n",
    "\n",
    "            val_loss /= len(test_loader)\n",
    "            val_acc /= len(test_loader)\n",
    "\n",
    "        print(f\"Epoch: {epoch} | Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}% | Val loss: {val_loss:.5f}, Val acc: {val_acc:.2f}%\")\n",
    "        train_losses.append(round(train_loss.item(), 3))\n",
    "        train_accs.append(round(train_acc.item(), 3))\n",
    "        val_losses.append(round(val_loss.item(), 3))\n",
    "        val_accs.append(round(val_acc.item(), 3))\n",
    "        \n",
    "    return train_losses, train_accs, val_losses, val_accs\n",
    "\n",
    "\n",
    "def evaluate_model(model):\n",
    "    \"\"\"\n",
    "    Util function for evaluating pyTorch model, i.e. returning predictions\n",
    "    \n",
    "    Args:\n",
    "        model: torch model instance\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        y_logits = model(X_test_tensor)\n",
    "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "        \n",
    "    return y_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f51db78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:47.418033Z",
     "start_time": "2023-11-30T16:27:47.332855Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1391381008cc4017be6291a074207dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 1.17898 | Train acc: 0.34% | Val loss: 0.99695, Val acc: 0.72%\n",
      "Epoch: 1 | Train loss: 1.04611 | Train acc: 0.42% | Val loss: 1.00933, Val acc: 0.36%\n",
      "Epoch: 2 | Train loss: 0.97937 | Train acc: 0.57% | Val loss: 0.94357, Val acc: 0.64%\n",
      "Epoch: 3 | Train loss: 0.91316 | Train acc: 0.72% | Val loss: 0.86912, Val acc: 0.64%\n",
      "Epoch: 4 | Train loss: 0.85918 | Train acc: 0.78% | Val loss: 0.80718, Val acc: 0.81%\n",
      "Epoch: 5 | Train loss: 0.80410 | Train acc: 0.74% | Val loss: 0.75446, Val acc: 0.72%\n",
      "Epoch: 6 | Train loss: 0.76311 | Train acc: 0.66% | Val loss: 0.70279, Val acc: 0.72%\n",
      "Epoch: 7 | Train loss: 0.73427 | Train acc: 0.64% | Val loss: 0.65751, Val acc: 0.72%\n",
      "Epoch: 8 | Train loss: 0.68466 | Train acc: 0.68% | Val loss: 0.62150, Val acc: 0.76%\n",
      "Epoch: 9 | Train loss: 0.62407 | Train acc: 0.76% | Val loss: 0.59265, Val acc: 0.93%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "train_losses, train_accs, val_losses, val_accs = train_model(model, epochs=EPOCHS)\n",
    "y_pred = evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71ad7ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:47.961386Z",
     "start_time": "2023-11-30T16:27:47.921922Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'batch_size': BATCH_SIZE, 'epochs': EPOCHS, 'learning_rate': LEARNING_RATE}\n",
    "metrics = {\n",
    "    'train_loss': round(train_losses[-1], 3),\n",
    "    'train_acc': round(train_accs[-1], 3),\n",
    "    'val_loss': round(val_losses[-1], 3),\n",
    "    'val_acc': round(val_accs[-1], 3)\n",
    "}\n",
    "torch_monitored = MonitoredModelWrapper(model=model)\n",
    "with open('../test_files/torch_model.pkl', 'wb') as f:\n",
    "    pickle.dump(torch_monitored, f)\n",
    "\n",
    "with start_iteration(iteration_name='NN v1') as iteration:\n",
    "    iteration.log_parameters(parameters=parameters)\n",
    "    iteration.log_metrics(metrics=metrics)\n",
    "    iteration.log_dataset(dataset_id=dataset_v1['_id'])\n",
    "    iteration.log_path_to_model(os.path.abspath('../test_files/torch_model.pkl'))\n",
    "    \n",
    "    iteration.log_chart(\n",
    "        chart_name=\"Loss\", chart_type=\"line\",\n",
    "        x_data=[[i for i in range(len(train_losses))]],\n",
    "        y_data=[train_losses, val_losses],\n",
    "        y_data_names=['training loss', 'validation loss'],\n",
    "        x_label=\"epochs\", y_label=\"Loss\", \n",
    "        chart_title='Training vs validation loss',\n",
    "        comparable=True)\n",
    "    \n",
    "    iteration.log_chart(\n",
    "        chart_name=\"Accuracy\", chart_type=\"line\",\n",
    "        x_data=[[i for i in range(len(train_losses))]],\n",
    "        y_data=[train_accs, val_accs],\n",
    "        y_data_names=['training acc', 'validation acc'],\n",
    "        x_label=\"epochs\", y_label=\"Loss\", \n",
    "        chart_title='Training vs validation accuracy',\n",
    "        comparable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df9a3585",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:27:48.834120Z",
     "start_time": "2023-11-30T16:27:48.819088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-length  sepal-width  petal-length  petal-width\n",
       "21            5.1          3.7           1.5          0.4\n",
       "7             5.0          3.4           1.5          0.2\n",
       "35            5.0          3.2           1.2          0.2\n",
       "23            5.1          3.3           1.7          0.5\n",
       "132           6.4          2.8           5.6          2.2\n",
       "..            ...          ...           ...          ...\n",
       "53            5.5          2.3           4.0          1.3\n",
       "22            4.6          3.6           1.0          0.2\n",
       "102           7.1          3.0           5.9          2.1\n",
       "136           6.3          3.4           5.6          2.4\n",
       "138           6.0          3.0           4.8          1.8\n",
       "\n",
       "[75 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43757a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:28:13.445596Z",
     "start_time": "2023-11-30T16:28:13.404778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '6568b81d8818cbb8a06e3cca',\n",
       "  'prediction_date': '2023-11-30T17:28:13.418971',\n",
       "  'input_data': {'sepal-length': 5.1,\n",
       "   'sepal-width': 3.7,\n",
       "   'petal-length': 1.5,\n",
       "   'petal-width': 0.4},\n",
       "  'prediction': 0.0,\n",
       "  'actual': None},\n",
       " {'id': '6568b81d8818cbb8a06e3ccb',\n",
       "  'prediction_date': '2023-11-30T17:28:13.421973',\n",
       "  'input_data': {'sepal-length': 5.0,\n",
       "   'sepal-width': 3.4,\n",
       "   'petal-length': 1.5,\n",
       "   'petal-width': 0.2},\n",
       "  'prediction': 0.0,\n",
       "  'actual': None},\n",
       " {'id': '6568b81d8818cbb8a06e3ccc',\n",
       "  'prediction_date': '2023-11-30T17:28:13.425486',\n",
       "  'input_data': {'sepal-length': 5.0,\n",
       "   'sepal-width': 3.2,\n",
       "   'petal-length': 1.2,\n",
       "   'petal-width': 0.2},\n",
       "  'prediction': 0.0,\n",
       "  'actual': None},\n",
       " {'id': '6568b81d8818cbb8a06e3ccd',\n",
       "  'prediction_date': '2023-11-30T17:28:13.429485',\n",
       "  'input_data': {'sepal-length': 5.1,\n",
       "   'sepal-width': 3.3,\n",
       "   'petal-length': 1.7,\n",
       "   'petal-width': 0.5},\n",
       "  'prediction': 0.0,\n",
       "  'actual': None},\n",
       " {'id': '6568b81d8818cbb8a06e3cce',\n",
       "  'prediction_date': '2023-11-30T17:28:13.432486',\n",
       "  'input_data': {'sepal-length': 6.4,\n",
       "   'sepal-width': 2.8,\n",
       "   'petal-length': 5.6,\n",
       "   'petal-width': 2.2},\n",
       "  'prediction': 2.0,\n",
       "  'actual': None}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlops.monitoring import send_prediction\n",
    "\n",
    "send_prediction(\n",
    "    model_name='Iris Torch',\n",
    "    data=X_test[:5]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c068376c",
   "metadata": {},
   "source": [
    "### 2nd iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "720d3987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:28:32.351853Z",
     "start_time": "2023-11-30T16:28:32.343846Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "HIDDEN_UNITS=100\n",
    "LEARNING_RATE=0.001\n",
    "\n",
    "model = BaselineNN(input_shape=X_train.shape[1],\n",
    "                   hidden_units=HIDDEN_UNITS,\n",
    "                   output_shape=pd.Series(y).nunique())\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ede04ef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:28:33.097719Z",
     "start_time": "2023-11-30T16:28:33.000071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c537cd866da5474990b704a1cab75370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 1.13291 | Train acc: 0.35% | Val loss: 1.04898, Val acc: 0.64%\n",
      "Epoch: 1 | Train loss: 1.01002 | Train acc: 0.66% | Val loss: 0.97090, Val acc: 0.72%\n",
      "Epoch: 2 | Train loss: 0.95823 | Train acc: 0.70% | Val loss: 0.92601, Val acc: 0.72%\n",
      "Epoch: 3 | Train loss: 0.96286 | Train acc: 0.64% | Val loss: 0.89495, Val acc: 0.72%\n",
      "Epoch: 4 | Train loss: 0.93175 | Train acc: 0.64% | Val loss: 0.86333, Val acc: 0.72%\n",
      "Epoch: 5 | Train loss: 0.88424 | Train acc: 0.66% | Val loss: 0.83263, Val acc: 0.72%\n",
      "Epoch: 6 | Train loss: 0.85016 | Train acc: 0.66% | Val loss: 0.80585, Val acc: 0.72%\n",
      "Epoch: 7 | Train loss: 0.82462 | Train acc: 0.64% | Val loss: 0.78180, Val acc: 0.80%\n",
      "Epoch: 8 | Train loss: 0.79088 | Train acc: 0.91% | Val loss: 0.76002, Val acc: 0.88%\n",
      "Epoch: 9 | Train loss: 0.75958 | Train acc: 0.91% | Val loss: 0.73725, Val acc: 0.86%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "train_losses, train_accs, val_losses, val_accs = train_model(model, epochs=EPOCHS)\n",
    "y_pred = evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cfb9081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:28:33.553173Z",
     "start_time": "2023-11-30T16:28:33.524160Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'batch_size': BATCH_SIZE, 'epochs': EPOCHS, 'learning_rate': LEARNING_RATE}\n",
    "metrics = {\n",
    "    'train_loss': round(train_losses[-1], 3),\n",
    "    'train_acc': round(train_accs[-1], 3),\n",
    "    'val_loss': round(val_losses[-1], 3),\n",
    "    'val_acc': round(val_accs[-1], 3)\n",
    "}\n",
    "\n",
    "with start_iteration(iteration_name='NN v2') as iteration:\n",
    "    iteration.log_parameters(parameters=parameters)\n",
    "    iteration.log_metrics(metrics=metrics)\n",
    "    iteration.log_dataset(dataset_id=dataset_v1['_id'])\n",
    "    \n",
    "    iteration.log_chart(\n",
    "        chart_name=\"Loss\", chart_type=\"line\",\n",
    "        x_data=[[i for i in range(len(train_losses))]],\n",
    "        y_data=[train_losses, val_losses],\n",
    "        y_data_names=['training loss', 'validation loss'],\n",
    "        x_label=\"epochs\", y_label=\"Loss\", \n",
    "        chart_title='Training vs validation loss',\n",
    "        comparable=True)\n",
    "    \n",
    "    iteration.log_chart(\n",
    "        chart_name=\"Accuracy\", chart_type=\"line\",\n",
    "        x_data=[[i for i in range(len(train_losses))]],\n",
    "        y_data=[train_accs, val_accs],\n",
    "        y_data_names=['training acc', 'validation acc'],\n",
    "        x_label=\"epochs\", y_label=\"Loss\", \n",
    "        chart_title='Training vs validation accuracy',\n",
    "        comparable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd674434",
   "metadata": {},
   "source": [
    "## Creating iterations with Image Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "506f7d11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:28:34.280358Z",
     "start_time": "2023-11-30T16:28:34.253795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Active experiment set to: 6568b8328818cbb8a06e3cd5'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = create_experiment(\n",
    "    name=\"Iterations with image charts\",\n",
    "    description=\"Iterations with image charts showcase\"\n",
    ")\n",
    "\n",
    "set_active_experiment(experiment_id=experiment['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86961f2b",
   "metadata": {},
   "source": [
    "### 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37ab8c67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:28:35.102704Z",
     "start_time": "2023-11-30T16:28:35.063144Z"
    }
   },
   "outputs": [],
   "source": [
    "with start_iteration(\"Iteration with image v1\") as iteration:\n",
    "    iteration.log_parameter(\"n_estimators\", 150)\n",
    "    iteration.log_metric(\"RMSE\", 0.9)\n",
    "    iteration.log_metric(\"MAE\", 0.45)\n",
    "    iteration.log_image_chart(name=\"Image chart 1\", \n",
    "                              image_path='../test_files/plot-1.png')\n",
    "    iteration.log_image_chart(name=\"Image chart 2\", \n",
    "                              image_path='../test_files/plot-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b1dbc3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:28:35.703258Z",
     "start_time": "2023-11-30T16:28:35.675164Z"
    }
   },
   "outputs": [],
   "source": [
    "with start_iteration(\"Iteration with image v2\") as iteration:\n",
    "    iteration.log_parameter(\"n_estimators\", 225)\n",
    "    iteration.log_metric(\"RMSE\", 0.8)\n",
    "    iteration.log_metric(\"MAE\", 0.41)\n",
    "    iteration.log_image_chart(name=\"Image chart 3\", \n",
    "                              image_path='../test_files/plot-3.png')\n",
    "    iteration.log_image_chart(name=\"Image chart 4\", \n",
    "                              image_path='../test_files/plot-4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5d4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.828px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
